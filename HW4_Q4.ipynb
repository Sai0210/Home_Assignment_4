{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391,
          "referenced_widgets": [
            "2c76722a3846482d9bdcf0abaffccec8",
            "c2c5a763575b47c9abcd0de123974437",
            "b6e10394c4c6426eb9896007b5dec841",
            "5ec75a6ad40a4b5eb70f73f42cfe4cc6",
            "08191b99c8f84a00b5aa9e4d36eaaf50",
            "83ef748eb851462d8cab87c69a1a117e",
            "f87dc44fef2044749c6d8fb6d42e90ae",
            "80d4cc72896d4aa6af13cd87e2c577d1",
            "7d0dbaef6f7c4eb8a099fa003a994d9a",
            "ab9a9055bf2f48879ac863e70f1d3b79",
            "21ce8a4f98384a5782d236d53401ec17",
            "e389b6067abe4008b55e5494ca89ca31",
            "990978e0594442328084cdb6f391c3e0",
            "32db1e07b7d3404cbd97dd11ac8671b4",
            "f2473046bb6446cf903aa3e0aa6716a1",
            "848672554e4f409fb26c905ac13a5474",
            "56d5406bb8734342a2de700ff800f349",
            "dec249cbe2ab460dadaa7caab9e016a9",
            "3799df4f75d2432dbbccf62638e09531",
            "89bdfce058e84e4db244802b0a774c4e",
            "79f1ae49089d405c8eaed4fbfc1290b4",
            "af80fd9fe9fc46ac82f499fceaa000ab",
            "d61d67c045db439db669fa4adad36ed8",
            "7dfeb21c5a924ce4958c5543d157d597",
            "0a52a1c5ce9e407491ec7d0f279efee0",
            "57e69ca4dcd64ef6bbcc3cda1a167a5a",
            "b6b1c0d69421473880ba0834ea54d326",
            "55262bf2f2ac42c7afd75c8bcda9eca6",
            "329c5d38275b4c9faafdeff4be63b242",
            "850815224f5a473a9dc9641e0fe7da09",
            "a4fd9f375a2146a5b006c350c1dab3de",
            "3ceda877f4b44e11bc2cd0010bcc4cd2",
            "36a05ca00c664dc89fbf0fe98549e2f1",
            "9a8599e4e58e402ba995cbf88826e43d",
            "77a8dae0cc64471188f9e7f0020ae7a9",
            "c4b7bc05350e4a59abad647883079854",
            "40c3a2385e014d798a499084fcd6145a",
            "fe2d4f1385ca40a7b48d33be7e247709",
            "0b8e7d7925c942a8a13a2424d67b3d14",
            "18082d33c6e5475d88b3fda46ed964ce",
            "ecf390a5d7a4442282c68ac607eebcf4",
            "eabf15fadf78480d9ff15b704290bd36",
            "3c0f512d90064e9195f193d71c323c9f",
            "cd9ed1907ddc45cea82bc4332ec76c8e"
          ]
        },
        "id": "yvHbMXrZ9MMp",
        "outputId": "276ecd18-3653-4aba-92c1-a8f88ad5fbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c76722a3846482d9bdcf0abaffccec8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e389b6067abe4008b55e5494ca89ca31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d61d67c045db439db669fa4adad36ed8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a8599e4e58e402ba995cbf88826e43d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: POSITIVE\n",
            "Confidence Score: 0.9998\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def analyze_sentiment(sentence):\n",
        "\n",
        "    # Load the pre-trained sentiment analysis pipeline\n",
        "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "    # Analyze the sentence\n",
        "    result = sentiment_pipeline(sentence)[0]\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Sentiment: {result['label']}\")\n",
        "    print(f\"Confidence Score: {result['score']:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sentence = \"Despite the high price, the performance of the new MacBook is outstanding.\"\n",
        "    analyze_sentiment(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uFqzBMCg9RLB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
